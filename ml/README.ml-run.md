# Запуск скрипта run.sh
=====================================

## Навигация
------------

* [Описание скрипта](#Описание-скрипта)
* [Зависимости](#Зависимости)
* [Запуск скрипта](#Запуск-скрипта)
* [Параметры скрипта](#Параметры-скрипта)
* [Создание новой виртуальной среды Python](#Создание-новой-виртуальной-среды-Python)

## Описание скрипта
-------------------

Скрипт `scripts/run.sh` предназначен для запуска процесса подготовки и обработки данных для модели машинного обучения. Он выполняет следующие шаги:

* Активирует виртуальную среду Python
* Создает новую таксономию на основе файла `data/train_dataset_tag_video/baseline/train_data_categories.csv`
* Разделяет данные на обучающую и тестовую выборки
* Запускает процесс обработки данных для модели `scripts/pipelines/llm_hierarcial`
* Оценивает результаты обработки данных


## Зависимости
--------------

Скрипт зависит от следующих компонентов:

* Python 3.x
* Библиотеки из `requirements.ml.in`
* Видео данные ([небольшой кусок](https://lodmedia.hb.bizmrg.com/case_files/1128311/train_dataset_tag_video.zip), [все данные](https://lodmedia.hb.bizmrg.com/case_files/1128311/train_tag_video_2.zip))

Обновить/пересобрать python пакеты:

```
python3 -m venv ./venv 
./venv/bin/pip install pip-tools
./venv/bin/pip-compile requirements.ml.in -o requirements.ml.txt && ./venv/bin/pip-sync requirements.ml.txt
```

Убедитесь, что все зависимости установлены и настроены правильно перед запуском скрипта.

## Запуск скрипта
-----------------

Вообще поддерживается работа с HF и OpenAI like API.
Таким образом появляется возможность использовать множество возможных движков инференса. Мы выбрали vllm как представитель простого и быстрого бэкенда для LLM. Ниже небольшая инструкция по развертке на машине с GPU.


### Развертка моделей с помощью VLLM

Для развертки моделей с помощью VLLM необходимо выполнить следующие шаги:

#### 1. Создание виртуальной среды

Создайте новую директорию для VLLM и перейдите в нее:
```bash
mkdir vllm
cd vllm
```
Создайте виртуальную среду Python:
```bash
python3 -m venv./venv
```
Активируйте виртуальную среду:
```bash
source./venv/bin/activate
```
#### 2. Установка необходимых пакетов

Установите необходимые пакеты:
```bash
pip install -U vllm matplotlib "huggingface_hub[cli]"
```
#### 3. Авторизация в Hugging Face

Авторизируйтесь в Hugging Face:
```bash
huggingface-cli login
```
Введите Ваш токен.

#### 4. Развертка модели

Разверните модель с помощью VLLM. Примеры команд для развертки моделей:

* Модель для быстрой проверки (лучше запускать в tmux):
```bash
./venv/bin/vllm serve --device cuda --cpu-offload-gb 4 --api-key token-abc123 --dtype half --max-model-len 8192 neuralmagic/Qwen2-0.5B-Instruct-quantized.w8a16
```
* Модель для быстрой проверки (лучше запускать в tmux):
```bash
./venv/bin/vllm serve --device cuda --cpu-offload-gb 4 --api-key token-abc123 --dtype half --trust-remote-code Qwen/Qwen-VL-Chat
```
Замените `token-abc123` на Ваш токен.

### Подготовка данных и запуск скрипта

1. **Разместите видеофайлы** в директории: `data/train_dataset_tag_video/videos` и `data/test_tag_video/videos`
2. **Разместите файлы с текстовым описанием и тегами** в директории: `data/train_dataset_tag_video/baseline/train_data_categories.csv` и `data/test_tag_video/sample_submission.csv`
3. **Настройте виртуальную среду через requirements.ml.txt** (если не знаете как, см. секцию ниже)
4. **Запустите скрипт** с флагом предсказания (`PREDICT_ALL=true`):

```bash
OPENROUTER_API_KEY="<API_KEY>" OPENROUTER_BASE_URL="<OPEAN_AI_LIKE_URL>" PREDICT_ALL=true bash scripts/run_test.sh
```

## Параметры скрипта
--------------------

Скрипт принимает следующие параметры:

* `DEBUG`: флаг отладки, по умолчанию `false`
* `PREDICT_ALL`: флаг предсказания, по умолчанию `false`
* `PIPELINE_NAME`: имя конвейера, по умолчанию `llm_hierarcial`
* `MODEL_TYPE`: тип модели, по умолчанию `openrouter`
* `HF_MODEL_NAME`: имя модели из библиотеки Hugging Face, по умолчанию `unsloth/Llama-3.2-1B-Instruct`
* `OPENROUTER_API_KEY`: ключ API для OpenRouter/vllm, по умолчанию `none`
* `OPENROUTER_BASE_URL`: базовый URL для OpenRouter/vllm, по умолчанию `https://openrouter.ai/api/v1/`
* `OPENROUTER_MODEL_NAME`: имя модели для OpenRouter/vllm, по умолчанию `meta-llama/llama-3.1-70b-instruct`


# Создание новой виртуальной среды Python
=====================================

## Зачем нужна виртуальная среда?
--------------------------------

Виртуальная среда Python позволяет создать изолированное окружение для вашего проекта, в котором можно устанавливать зависимости и библиотеки без влияния на системную среду Python.

## Создание новой виртуальной среды
---------------------------------

Чтобы создать новую виртуальную среду Python, выполните следующие шаги:

1. Откройте терминал и перейдите в директорию, где вы хотите создать виртуальную среду.
2. Выполните команду `python -m venv venv`, где `venv` - имя вашей виртуальной среды.

````bash
python -m venv venv
````

Это создаст новую виртуальную среду с именем `venv` в текущей директории.

## Активация виртуальной среды
-----------------------------

Чтобы активировать виртуальную среду, выполните команду `source venv/bin/activate` (на Linux/Mac) или `venv\Scripts\activate` (на Windows).

````bash
source venv/bin/activate
````

После активации виртуальной среды, вы увидите имя среды в начале командной строки.

## Установка зависимостей
-------------------------

После активации виртуальной среды, вы можете устанавливать зависимости и библиотеки, необходимые для вашего проекта, используя команду `pip install`.

````bash
pip install -r requirements.ml.txt
````

## Деактивация виртуальной среды
------------------------------

Чтобы деактивировать виртуальную среду, выполните команду `deactivate`.

````bash
deactivate
````

После деактивации виртуальной среды, вы вернетесь в системную среду Python.
